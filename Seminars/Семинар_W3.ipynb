{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esis-a-i/Data-Engineering-Arenadata/blob/main/Seminars/%D0%A1%D0%B5%D0%BC%D0%B8%D0%BD%D0%B0%D1%80_W3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62c2f9cc-d2d9-4b61-b0c1-9d85cf8020df",
      "metadata": {
        "id": "62c2f9cc-d2d9-4b61-b0c1-9d85cf8020df"
      },
      "source": [
        "# Работа с HDFS: создание директории, загрузка файлов в HDFS\n",
        "\n",
        "Семинар 2. Основные концепции\n",
        "\n",
        "Елена Дорофеева. Аренадата Софтвер"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7096b41-91ff-4e25-903c-3f1b0bdbfec9",
      "metadata": {
        "id": "f7096b41-91ff-4e25-903c-3f1b0bdbfec9"
      },
      "source": [
        "## Цель семинара\n",
        "\n",
        "Познакомить участников с основными командами для работы с HDFS в Hadoop, научить их создавать директории, загружать файлы и управлять ими в распределённой файловой системе."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b1b40a9-e9d4-4441-9a0b-cc99f6bb2f40",
      "metadata": {
        "id": "5b1b40a9-e9d4-4441-9a0b-cc99f6bb2f40"
      },
      "source": [
        "## План семинара\n",
        "\n",
        "\n",
        "1.   Введение в HDFS:\n",
        "  \n",
        "  1.1. Подключение к HDFS: подключение к кластеру Hadoop и проверка доступа к HDFS.\n",
        "      \n",
        "  1.2. Разрешения в HDFS.\n",
        "      \n",
        "  1.3. Основные команды HDFS: обзор команд для работы с HDFS (hdfs dfs и hadoop fs).\n",
        "2.   Работа с директориями в HDFS:\n",
        "  \n",
        "  2.1. Создание директории.\n",
        "  \n",
        "  2.2. Просмотр содержимого директории.\n",
        "3. Команды скачивания и загрузки файлов:\n",
        "  \n",
        "  3.1. Выгрузка файлов из HDFS.\n",
        "  \n",
        "  3.2. Загрузка файлов в HDFS.\n",
        "4. Команды для чтения файлов в HDFS.\n",
        "5. Управление данными в HDFS:\n",
        "  \n",
        "  5.1. Перемещение и копирование файлов.\n",
        "  \n",
        "  5.2. Удаление файлов и директорий.\n",
        "6. Аналитика утилизации хранилища\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd9ed98c-b7d3-4f3e-b8df-c716e2d5105a",
      "metadata": {
        "id": "bd9ed98c-b7d3-4f3e-b8df-c716e2d5105a"
      },
      "source": [
        "## 1. Введение в HDFS\n",
        "### 1.1. Подключение к HDFS: подключение к кластеру Hadoop и проверка доступа к HDFS\n",
        "\n",
        "Чтобы работать в Hadoop, нужно стать пользователем Hadoop. Им можно стать с помощью создания домашней директории и наделения твоего пользователя полномочиями на эту директорию.\n",
        "\n",
        "Это делается двумя командами: mkdir и chown. Это обязательное действие, если ты хочешь работать в&nbsp;Hadoop."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e3e914d-7061-4aae-a662-e151ff7174d1",
      "metadata": {
        "id": "0e3e914d-7061-4aae-a662-e151ff7174d1"
      },
      "source": [
        "sudo -u hdfs — синтаксис команды, чтобы создать первоначальную директорию и наделить её правами.\n",
        "Для этого нам нужны привилегии суперпользователя."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "863c5a09-03c8-4b71-a81b-29415fd51992",
      "metadata": {
        "id": "863c5a09-03c8-4b71-a81b-29415fd51992"
      },
      "source": [
        "Cоздаём домашнюю директорию:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc053871-5d10-4e89-aa98-fdce50d32df1",
      "metadata": {
        "id": "cc053871-5d10-4e89-aa98-fdce50d32df1"
      },
      "outputs": [],
      "source": [
        "sudo -u hdfs hadoop fs -mkdir /user/admin\n",
        "sudo -u hdfs hadoop fs -chown admin:admin /user/admin"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22e9ea19-c9c3-4f18-ba4d-fa5381a5daa4",
      "metadata": {
        "id": "22e9ea19-c9c3-4f18-ba4d-fa5381a5daa4"
      },
      "source": [
        "Наделяем твоего пользователя полномочиями на эту директорию:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "516c567e-df0f-437d-81ce-89b010477264",
      "metadata": {
        "id": "516c567e-df0f-437d-81ce-89b010477264"
      },
      "outputs": [],
      "source": [
        "sudo -u hdfs hadoop fs -chown admin:admin /user/admin"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34b6fa21-199a-49c8-b29c-5cba8a7ab398",
      "metadata": {
        "id": "34b6fa21-199a-49c8-b29c-5cba8a7ab398"
      },
      "source": [
        "Что будет, если у тебя не будет домашней директории:\n",
        "1. Ты не сможешь создавать директории в HDFS (будет выведена ошибка, например:\n",
        "mkdir: Permission denied: user=teacher_1, access=WRITE, inode=\"/\":hdfs:hadoop:drwxr-xr-x).\n",
        "2. Ты не сможешь запускать задачи MapReduce на вычисление, так как у YARN есть обязательное условие, чтобы была домашняя директория. Когда мы из-под пользователя запускаем задачу MapReduce, она сохраняет промежуточные результаты в твою домашнюю директорию."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bbf3f49-d6b5-4aaa-aaea-5d0002af55a6",
      "metadata": {
        "id": "4bbf3f49-d6b5-4aaa-aaea-5d0002af55a6"
      },
      "source": [
        "### 1.2. Разрешения в HDFS\n",
        "\n",
        "Каждому файлу и директории в HDFS присваивается владелец (owner), группа (group) и разрешения (permissions).\n",
        "Разрешения включают три уровня доступа:\n",
        "\n",
        "*   чтение (read);\n",
        "*   запись (write);\n",
        "*   выполнение (execute).\n",
        "\n",
        "Разрешения задаются для трёх категорий пользователей: владельца (owner), группы (group) и других (others)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05ff85d7-26e1-49ff-abf6-f27a1260586a",
      "metadata": {
        "id": "05ff85d7-26e1-49ff-abf6-f27a1260586a"
      },
      "source": [
        "Посмотрим на разрешения на файлы и директории в корневой директории, а также на их владельцев и&nbsp;группы:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c077653b-c808-47e8-845a-b024cde6464e",
      "metadata": {
        "id": "c077653b-c808-47e8-845a-b024cde6464e",
        "outputId": "5da1fb46-49b7-477e-fb31-02bd021963f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 9 items\n",
            "drwxrwxrwx   - hdfs hadoop          0 2024-10-21 18:21 /ETL\n",
            "drwxr-xr-x   - hdfs hadoop          0 2024-07-10 10:29 /apps\n",
            "drwx------   - livy hadoop          0 2024-07-10 10:30 /livy-recovery\n",
            "drwx------   - livy hadoop          0 2024-07-10 10:29 /livy-spark3-recovery\n",
            "drwxrwxrwt   - yarn hadoop          0 2024-10-21 08:59 /logs\n",
            "drwxr-xr-x   - hdfs hadoop          0 2024-07-10 10:19 /system\n",
            "drwxrwxrwx   - hdfs hadoop          0 2024-10-29 05:44 /tmp\n",
            "drwxr-xr-x   - hdfs hadoop          0 2024-07-12 11:48 /user\n",
            "drwxr-xr-x   - hdfs hadoop          0 2024-07-10 10:28 /var\n"
          ]
        }
      ],
      "source": [
        "!hadoop fs -ls /"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dfc53c4-bc69-407b-b63c-9e6cb1306335",
      "metadata": {
        "id": "2dfc53c4-bc69-407b-b63c-9e6cb1306335",
        "outputId": "0ce05a96-535c-4b21-ca4f-a3f6f2359e83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "drwxr-xr-x   - educator  educator           0 2024-07-11 07:32 /user/educator\n",
            "drwx------   - hdfs      hadoop             0 2024-07-11 06:22 /user/hdfs\n",
            "ls: Permission denied: user=educator, access=READ_EXECUTE, inode=\"/user/hdfs\":hdfs:hadoop:drwx------\n",
            "drwxr-xr-x   - mapred    hadoop             0 2024-07-10 10:19 /user/history\n",
            "drwxrwx---   - mapred    hadoop             0 2024-07-10 12:19 /user/history/done\n",
            "ls: Permission denied: user=educator, access=READ_EXECUTE, inode=\"/user/history/done\":mapred:hadoop:drwxrwx---\n",
            "drwxrwxrwt   - mapred    hadoop             0 2024-09-06 15:07 /user/history/done_intermediate\n",
            "drwxrwx---   - hdfs      hadoop             0 2024-07-11 06:16 /user/history/done_intermediate/hdfs\n",
            "ls: Permission denied: user=educator, access=READ_EXECUTE, inode=\"/user/history/done_intermediate/hdfs\":hdfs:hadoop:drwxrwx---\n",
            "drwxrwx---   - teacher_1 hadoop             0 2024-09-23 11:46 /user/history/done_intermediate/teacher_1\n",
            "ls: Permission denied: user=educator, access=READ_EXECUTE, inode=\"/user/history/done_intermediate/teacher_1\":teacher_1:hadoop:drwxrwx---\n",
            "drwxrwx---   - yarn      hadoop             0 2024-07-11 06:13 /user/history/done_intermediate/yarn\n",
            "ls: Permission denied: user=educator, access=READ_EXECUTE, inode=\"/user/history/done_intermediate/yarn\":yarn:hadoop:drwxrwx---\n",
            "drwxr-xr-x   - hive      hadoop             0 2024-07-10 12:21 /user/hive\n",
            "drwx------   - hive      hadoop             0 2024-10-11 08:00 /user/hive/.Trash\n",
            "ls: Permission denied: user=educator, access=READ_EXECUTE, inode=\"/user/hive/.Trash\":hive:hadoop:drwx------\n",
            "drwxr-xr-x   - hive      hadoop             0 2024-07-10 10:26 /user/hive/.hiveJars\n",
            "-rw-r--r--   3 hive      hadoop      43845891 2024-07-10 10:26 /user/hive/.hiveJars/hive-exec-3.1.3-a9484e55eca2fe4d4675e63a1824bd15a7cf723ac41b7ebe2414b886b2c87295.jar\n",
            "drwxr-xr-x   - livy      hadoop             0 2024-07-10 10:29 /user/livy\n",
            "drwxr-xr-x   - mapred    mapred             0 2024-07-10 10:19 /user/mapred\n",
            "drwxr-xr-x   - spark     hadoop             0 2024-07-10 12:21 /user/spark\n",
            "drwxr-xr-x   - spark     hadoop             0 2024-07-11 06:22 /user/spark/.sparkStaging\n",
            "drwxr-xr-x   - student1  student1           0 2024-07-11 12:47 /user/student1\n",
            "drwxr-xr-x   - student2  student2           0 2024-07-11 13:48 /user/student2\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-10-08 12:29 /user/teacher_1\n",
            "drwx------   - teacher_1 teacher_1          0 2024-09-05 15:00 /user/teacher_1/.Trash\n",
            "ls: Permission denied: user=educator, access=READ_EXECUTE, inode=\"/user/teacher_1/.Trash\":teacher_1:teacher_1:drwx------\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-10-21 19:00 /user/teacher_1/.sparkStaging\n",
            "drwx------   - teacher_1 teacher_1          0 2024-09-23 11:46 /user/teacher_1/.staging\n",
            "ls: Permission denied: user=educator, access=READ_EXECUTE, inode=\"/user/teacher_1/.staging\":teacher_1:teacher_1:drwx------\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-06 15:07 /user/teacher_1/testload\n",
            "-rw-r--r--   3 teacher_1 teacher_1    1475504 2024-09-06 11:02 /user/teacher_1/testload/data.csv\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-06 15:07 /user/teacher_1/testload/output\n",
            "-rw-r--r--   3 teacher_1 teacher_1          0 2024-09-06 15:07 /user/teacher_1/testload/output/_SUCCESS\n",
            "-rw-r--r--   3 teacher_1 teacher_1        552 2024-09-06 15:07 /user/teacher_1/testload/output/part-r-00000\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-10-10 07:26 /user/teacher_1/testload1\n",
            "-rw-r--r--   3 teacher_1 teacher_1    1475504 2024-10-10 07:26 /user/teacher_1/testload1/data.csv\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:12 /user/teacher_1/tmp\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-23 11:46 /user/teacher_1/tmp/mrjob\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:12 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131159.994286\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:12 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131159.994286/files\n",
            "-rw-r--r--   3 teacher_1 teacher_1     430391 2024-09-13 13:12 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131159.994286/files/mrjob.zip\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:12 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131159.994286/files/wd\n",
            "-rw-r--r--   3 teacher_1 teacher_1       1130 2024-09-13 13:12 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131159.994286/files/wd/MRLineCount.py\n",
            "-rw-r--r--   3 teacher_1 teacher_1     430391 2024-09-13 13:12 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131159.994286/files/wd/mrjob.zip\n",
            "-rw-r--r--   3 teacher_1 teacher_1        391 2024-09-13 13:12 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131159.994286/files/wd/setup-wrapper.sh\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:12 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131217.640831\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:12 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131217.640831/files\n",
            "-rw-r--r--   3 teacher_1 teacher_1     430391 2024-09-13 13:12 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131217.640831/files/mrjob.zip\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:12 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131217.640831/files/wd\n",
            "-rw-r--r--   3 teacher_1 teacher_1       1130 2024-09-13 13:12 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131217.640831/files/wd/MRLineCount.py\n",
            "-rw-r--r--   3 teacher_1 teacher_1     430391 2024-09-13 13:12 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131217.640831/files/wd/mrjob.zip\n",
            "-rw-r--r--   3 teacher_1 teacher_1        391 2024-09-13 13:12 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131217.640831/files/wd/setup-wrapper.sh\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:13 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131217.640831/output\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:13 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131321.750618\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:13 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131321.750618/files\n",
            "-rw-r--r--   3 teacher_1 teacher_1     430391 2024-09-13 13:13 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131321.750618/files/mrjob.zip\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:13 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131321.750618/files/wd\n",
            "-rw-r--r--   3 teacher_1 teacher_1       1130 2024-09-13 13:13 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131321.750618/files/wd/MRLineCount.py\n",
            "-rw-r--r--   3 teacher_1 teacher_1     430391 2024-09-13 13:13 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131321.750618/files/wd/mrjob.zip\n",
            "-rw-r--r--   3 teacher_1 teacher_1        391 2024-09-13 13:13 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131321.750618/files/wd/setup-wrapper.sh\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:14 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131321.750618/output\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:15 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131505.223673\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:15 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131505.223673/files\n",
            "-rw-r--r--   3 teacher_1 teacher_1     430391 2024-09-13 13:15 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131505.223673/files/mrjob.zip\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:15 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131505.223673/files/wd\n",
            "-rw-r--r--   3 teacher_1 teacher_1       1130 2024-09-13 13:15 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131505.223673/files/wd/MRLineCount.py\n",
            "-rw-r--r--   3 teacher_1 teacher_1     430391 2024-09-13 13:15 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131505.223673/files/wd/mrjob.zip\n",
            "-rw-r--r--   3 teacher_1 teacher_1        391 2024-09-13 13:15 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131505.223673/files/wd/setup-wrapper.sh\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:15 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131505.223673/output\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:18 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131751.675041\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:18 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131751.675041/files\n",
            "-rw-r--r--   3 teacher_1 teacher_1     430391 2024-09-13 13:18 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131751.675041/files/mrjob.zip\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:18 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131751.675041/files/wd\n",
            "-rw-r--r--   3 teacher_1 teacher_1       1287 2024-09-13 13:17 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131751.675041/files/wd/MRLineCount.py\n",
            "-rw-r--r--   3 teacher_1 teacher_1     430391 2024-09-13 13:17 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131751.675041/files/wd/mrjob.zip\n",
            "-rw-r--r--   3 teacher_1 teacher_1        391 2024-09-13 13:18 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131751.675041/files/wd/setup-wrapper.sh\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:18 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131751.675041/output\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:19 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131920.208593\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:19 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131920.208593/files\n",
            "-rw-r--r--   3 teacher_1 teacher_1     430391 2024-09-13 13:19 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131920.208593/files/mrjob.zip\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:19 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131920.208593/files/wd\n",
            "-rw-r--r--   3 teacher_1 teacher_1       1287 2024-09-13 13:19 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131920.208593/files/wd/MRLineCount.py\n",
            "-rw-r--r--   3 teacher_1 teacher_1     430391 2024-09-13 13:19 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131920.208593/files/wd/mrjob.zip\n",
            "-rw-r--r--   3 teacher_1 teacher_1        391 2024-09-13 13:19 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131920.208593/files/wd/setup-wrapper.sh\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:20 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.131920.208593/output\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:21 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.132109.092663\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:21 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.132109.092663/files\n",
            "-rw-r--r--   3 teacher_1 teacher_1     430391 2024-09-13 13:21 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.132109.092663/files/mrjob.zip\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:21 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.132109.092663/files/wd\n",
            "-rw-r--r--   3 teacher_1 teacher_1       1287 2024-09-13 13:21 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.132109.092663/files/wd/MRLineCount.py\n",
            "-rw-r--r--   3 teacher_1 teacher_1     430391 2024-09-13 13:21 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.132109.092663/files/wd/mrjob.zip\n",
            "-rw-r--r--   3 teacher_1 teacher_1        391 2024-09-13 13:21 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.132109.092663/files/wd/setup-wrapper.sh\n",
            "drwxr-xr-x   - teacher_1 teacher_1          0 2024-09-13 13:21 /user/teacher_1/tmp/mrjob/MRLineCount.teacher_1.20240913.132109.092663/output\n",
            "drwxr-xr-x   - teacher_2 teacher_2          0 2024-07-12 11:47 /user/teacher_2\n",
            "drwxr-xr-x   - teacher_3 teacher_3          0 2024-07-12 11:48 /user/teacher_3\n",
            "drwxr-xr-x   - teacher_4 teacher_4          0 2024-07-12 11:48 /user/teacher_4\n",
            "drwxr-xr-x   - teacher_5 teacher_5          0 2024-07-12 11:48 /user/teacher_5\n",
            "drwxr-xr-x   - yarn      yarn               0 2024-07-11 06:13 /user/yarn\n",
            "drwx------   - yarn      yarn               0 2024-07-11 06:13 /user/yarn/.staging\n",
            "ls: Permission denied: user=educator, access=READ_EXECUTE, inode=\"/user/yarn/.staging\":yarn:yarn:drwx------\n",
            "drwxr-xr-x   - zeppelin  hadoop             0 2024-07-10 10:14 /user/zeppelin\n"
          ]
        }
      ],
      "source": [
        "!hdfs dfs -ls -R /user\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a084aed-ce56-4f3e-8132-0bd4c5a81507",
      "metadata": {
        "id": "4a084aed-ce56-4f3e-8132-0bd4c5a81507"
      },
      "source": [
        "Разбор вывода:\n",
        "\n",
        "*   Первая колонка показывает права доступа, например: -rw-r--r--, r — чтение, w — запись, x — выполнение.\n",
        "*   Первая часть (например, rw-) относится к владельцу.\n",
        "*   Вторая часть (r--) относится к группе.\n",
        "*   Третья часть (r--) относится к другим пользователям.\n",
        "*   Далее идёт владелец файла и группа."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b3c567e-3790-42de-a32e-3760d19db34c",
      "metadata": {
        "id": "9b3c567e-3790-42de-a32e-3760d19db34c"
      },
      "source": [
        "Например, разрешение drwxrwxrwx означает, что всем можно всё."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34da70d9-dc34-43d5-bc08-2c6dd517579a",
      "metadata": {
        "id": "34da70d9-dc34-43d5-bc08-2c6dd517579a"
      },
      "source": [
        "Таким образом, файлы в HDFS можно читать, удалять, записывать, перезаписывать, но нельзя изменять. И нельзя запустить на выполнение файл.\n",
        "Режимы доступа такие же, как и в Linux, но с «х» некоторые проблемы. А именно: для файлов «х» игнорируется, а для каталогов это разрешение даёт возможность проваливаться вниз каталога."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27f7db24-6ab0-4b50-892b-3c9fac566a26",
      "metadata": {
        "id": "27f7db24-6ab0-4b50-892b-3c9fac566a26"
      },
      "source": [
        "### 1.3. Основные команды HDFS: обзор команд для работы с HDFS (hdfs dfs и hadoop fs)\n",
        "\n",
        "Для взаимодействия с HDFS используются команды, аналогичные стандартным UNIX-командам, через утилиты hdfs dfs и hadoop fs.\n",
        "Команды hdfs dfs и hadoop fs практически идентичны в использовании и предлагают одни и те же функции.\n",
        "hdfs dfs используется специально для работы с HDFS, в том числе поддерживает команды для администрирования.\n",
        "hadoop fs является более универсальной командой, которая может работать с различными файловыми системами, поддерживаемыми Hadoop."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7462ad3c-91fd-47ea-b19d-ffb777d52b60",
      "metadata": {
        "id": "7462ad3c-91fd-47ea-b19d-ffb777d52b60"
      },
      "source": [
        "## 2. Работа с директориями в HDFS\n",
        "\n",
        "### 2.1. Создание директории\n",
        "\n",
        "Команда mkdir: создание новых директорий в HDFS."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c19b36ac-78da-4960-8276-4a7f102c74ca",
      "metadata": {
        "id": "c19b36ac-78da-4960-8276-4a7f102c74ca"
      },
      "source": [
        "Создаём директорию /user/yourname/testload:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "672b911b-4116-40f0-a0bf-76cf43612f31",
      "metadata": {
        "id": "672b911b-4116-40f0-a0bf-76cf43612f31"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -mkdir testload"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22759b20-a392-4ad7-a5f5-622c7f0ecbcb",
      "metadata": {
        "id": "22759b20-a392-4ad7-a5f5-622c7f0ecbcb"
      },
      "source": [
        "Проверяем наличие созданной директории:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad2765cc-4753-4159-8bc6-25e7375a94f4",
      "metadata": {
        "id": "ad2765cc-4753-4159-8bc6-25e7375a94f4"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -ls"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba718787-c278-4033-a825-7352aa2863ec",
      "metadata": {
        "id": "ba718787-c278-4033-a825-7352aa2863ec"
      },
      "source": [
        "### 2.2. Просмотр содержимого директории\n",
        "\n",
        "Команда ls: просмотр содержимого директории."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f829a935-f200-475b-9037-49cec6f207d6",
      "metadata": {
        "id": "f829a935-f200-475b-9037-49cec6f207d6"
      },
      "source": [
        "Проверяем содержимое директории /user/yourname/testload:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5d3f0e7-1e53-4ea8-94b6-4c925ff02c52",
      "metadata": {
        "id": "e5d3f0e7-1e53-4ea8-94b6-4c925ff02c52"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -ls testload"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "754bf391-4d4a-4137-8213-a4223e08d285",
      "metadata": {
        "id": "754bf391-4d4a-4137-8213-a4223e08d285"
      },
      "source": [
        "## 3. Команды скачивания и загрузки файлов\n",
        "\n",
        "### 3.1. Выгрузка файлов из HDFS\n",
        "\n",
        "Команда get: копирует файл из каталога HDFS в каталог локальной файловой системы.\n",
        "https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/FileSystemShell.html#get"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c936a14-cb4d-404f-b6ad-d9717b29f240",
      "metadata": {
        "id": "2c936a14-cb4d-404f-b6ad-d9717b29f240"
      },
      "source": [
        "Загружаем в свой текущий рабочий каталог файл из HDFS:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28db5cbc-a1b7-4cd3-9c24-0a1f14a9d7fe",
      "metadata": {
        "id": "28db5cbc-a1b7-4cd3-9c24-0a1f14a9d7fe"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -get /tmp/data.csv ~/data_from_hadoop.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b77f8a3-559f-4c8c-9f03-20e0d94a50f1",
      "metadata": {
        "id": "8b77f8a3-559f-4c8c-9f03-20e0d94a50f1"
      },
      "source": [
        "Проверяем наличие файла в текущем рабочем каталоге:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a0d882e-c4e8-41a9-b4fa-3efdbd945fe4",
      "metadata": {
        "id": "8a0d882e-c4e8-41a9-b4fa-3efdbd945fe4"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a99bdb77-fdb5-45c8-93c8-c0d322ce60a5",
      "metadata": {
        "id": "a99bdb77-fdb5-45c8-93c8-c0d322ce60a5"
      },
      "source": [
        "### 3.2. Загрузка файлов в HDFS\n",
        "\n",
        "Команда put: загрузка файлов из локальной файловой системы в HDFS.\n",
        "https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/FileSystemShell.html#put"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a50fafd-882f-4412-9167-f887bb13f0ac",
      "metadata": {
        "id": "7a50fafd-882f-4412-9167-f887bb13f0ac"
      },
      "source": [
        "Загружаем файл в HDFS, в ранее созданную директорию testload:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31fa2b60-9cac-4d62-a8c6-e5ada71c905c",
      "metadata": {
        "id": "31fa2b60-9cac-4d62-a8c6-e5ada71c905c"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -put /home/teacher_1/data_from_hadoop.csv testload/data.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c827118e-4bb2-4e3d-aa9b-358c3e02e428",
      "metadata": {
        "id": "c827118e-4bb2-4e3d-aa9b-358c3e02e428"
      },
      "source": [
        "Проверяем наличие файла в HDFS, в директории testload:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebb09f3b-5f65-4089-870f-cc230c4e01a5",
      "metadata": {
        "id": "ebb09f3b-5f65-4089-870f-cc230c4e01a5"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -ls /user/teacher_1/testload"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7f9b80c-e88f-4de5-9681-c70573eb0c33",
      "metadata": {
        "id": "c7f9b80c-e88f-4de5-9681-c70573eb0c33"
      },
      "source": [
        "## 4. Команды для чтения файлов в HDFS\n",
        "\n",
        "Команда cat выводит содержимое HDFS-файла в stdout (стандартный вывод на экран)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3da3f5b-8f2e-4793-bcd4-b6a862643da1",
      "metadata": {
        "id": "d3da3f5b-8f2e-4793-bcd4-b6a862643da1"
      },
      "source": [
        "Посмотрим содержимое файла, находящегося в директории testload:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b848570f-e7b2-4fe5-8f9e-a798e3927779",
      "metadata": {
        "id": "b848570f-e7b2-4fe5-8f9e-a798e3927779"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -cat /user/teacher_1/testload/data.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90671308-e132-4f31-9a3e-99f1ad503c34",
      "metadata": {
        "id": "90671308-e132-4f31-9a3e-99f1ad503c34"
      },
      "source": [
        "Команда head выводит первый килобайт файла в stdout (стандартный вывод на экран).\n",
        "Подходит, когда достаточно вывести первые несколько строк файла, а не открывать полностью весь большой файл:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99086ab0-b603-4711-8f6d-0309cff53800",
      "metadata": {
        "id": "99086ab0-b603-4711-8f6d-0309cff53800"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -head /user/teacher_1/testload/data.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f25f00ec-1b56-438b-bac8-832ccd60c578",
      "metadata": {
        "id": "f25f00ec-1b56-438b-bac8-832ccd60c578"
      },
      "source": [
        "Команда text принимает исходный файл и выводит файл в текстовом формате в stdout:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21f5656d-039d-4839-a6be-63dcabf2c066",
      "metadata": {
        "id": "21f5656d-039d-4839-a6be-63dcabf2c066"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -text /user/teacher_1/testload/data.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e54cf12-9fb0-4547-bd7a-9d4c4442a168",
      "metadata": {
        "id": "7e54cf12-9fb0-4547-bd7a-9d4c4442a168"
      },
      "source": [
        "## 5. Управление данными в HDFS\n",
        "\n",
        "### 5.1. Перемещение и копирование файлов"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36d5a008-4747-47fd-8433-22b8813cae36",
      "metadata": {
        "id": "36d5a008-4747-47fd-8433-22b8813cae36"
      },
      "source": [
        "Команда mv перемещает файлы из источника в место назначения в файловой системе HDFS. Позволяет указать несколько источников, в этом случае местом назначения должен быть каталог. Перемещение файлов между разными файловыми системами не допускается.\n",
        "Возвращает 0 при успешной попытке и -1 при ошибке.\n",
        "\n",
        "https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/FileSystemShell.html#mv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a4807a9-e626-4ec2-adca-bc3bb48ae509",
      "metadata": {
        "id": "0a4807a9-e626-4ec2-adca-bc3bb48ae509"
      },
      "source": [
        "Создаём в HDFS новую директорию testload1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ddfcd11-dd3b-4ca5-b8cc-8563d58efd87",
      "metadata": {
        "id": "8ddfcd11-dd3b-4ca5-b8cc-8563d58efd87"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -mkdir testload1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "915525a6-701f-4e71-b251-95d19cdffa1f",
      "metadata": {
        "id": "915525a6-701f-4e71-b251-95d19cdffa1f"
      },
      "source": [
        "Проверяем наличие созданной директории:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf7bb5ca-97fe-4a69-a02b-91d9c4a25808",
      "metadata": {
        "id": "bf7bb5ca-97fe-4a69-a02b-91d9c4a25808"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -ls"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdb3d27e-f71e-461e-aeee-97012f3867b1",
      "metadata": {
        "id": "cdb3d27e-f71e-461e-aeee-97012f3867b1"
      },
      "source": [
        "Перемещаем файл data.csv из директории testload в новую директорию testload1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfbaf32f-07fa-497e-aef3-fbb34bd70fe5",
      "metadata": {
        "id": "cfbaf32f-07fa-497e-aef3-fbb34bd70fe5"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -mv /user/teacher_1/testload/data.csv /user/teacher_1/testload1/data1.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e082243-b0a3-4da7-9eed-46972fb2889a",
      "metadata": {
        "id": "4e082243-b0a3-4da7-9eed-46972fb2889a"
      },
      "source": [
        "Проверяем в директории testload1 наличие файла data1.csv:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db1e2658-2d83-4e36-8d3f-bbe5c3738a05",
      "metadata": {
        "id": "db1e2658-2d83-4e36-8d3f-bbe5c3738a05"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -ls testload1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3969accc-7c0a-4c16-8c6b-51e12c393c00",
      "metadata": {
        "id": "3969accc-7c0a-4c16-8c6b-51e12c393c00"
      },
      "source": [
        "Проверяем отсутствие файла data.csv в директории testload (он должен переместиться):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6202efd2-7c21-43bd-baa1-acf3089ddab5",
      "metadata": {
        "id": "6202efd2-7c21-43bd-baa1-acf3089ddab5"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -ls testload"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c9c8eb3-6534-4eee-a895-fb15796b66d8",
      "metadata": {
        "id": "0c9c8eb3-6534-4eee-a895-fb15796b66d8"
      },
      "source": [
        "Команда cp копирует файлы из источника в место назначения.\n",
        "Команда позволяет использовать несколько источников, в этом случае местом назначения должен быть каталог.\n",
        "https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/FileSystemShell.html#cp"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f33ddd2-d3b7-4896-a759-bed604169f53",
      "metadata": {
        "id": "0f33ddd2-d3b7-4896-a759-bed604169f53"
      },
      "source": [
        "Копируем файл data1.csv из директории testload1 в директорию testload:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e01839cc-169b-4421-a4ac-7d047ce7e8f3",
      "metadata": {
        "id": "e01839cc-169b-4421-a4ac-7d047ce7e8f3"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -cp /user/teacher_1/testload1/data1.csv /user/teacher_1/testload/data.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d2836aa-3051-4370-8967-a3fd78934dbc",
      "metadata": {
        "id": "3d2836aa-3051-4370-8967-a3fd78934dbc"
      },
      "source": [
        "Проверяем наличие файла data.csv в директории testload:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03f41beb-cfcb-4736-8904-9cd9c7dba04c",
      "metadata": {
        "id": "03f41beb-cfcb-4736-8904-9cd9c7dba04c"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -ls testload"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9edd9ed6-f6d3-490f-8b04-0008d18429be",
      "metadata": {
        "id": "9edd9ed6-f6d3-490f-8b04-0008d18429be"
      },
      "source": [
        "Также проверяем наличие файла data1.csv в директории testload1 (он также должен быть, так как это копирование, а не перемещение):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88d6e6eb-fc80-4d9a-9987-8d9edc1feaf4",
      "metadata": {
        "id": "88d6e6eb-fc80-4d9a-9987-8d9edc1feaf4"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -ls testload1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11770cac-9af1-4881-b61d-626dd2cbac25",
      "metadata": {
        "id": "11770cac-9af1-4881-b61d-626dd2cbac25"
      },
      "source": [
        "### 5.2. Удаление файлов и директорий\n",
        "\n",
        "Есть два способа удаления файлов и директорий в HDFS: с перемещением в корзину (удаление с&nbsp;возможностью восстановления) и без перемещения в корзину (необратимое удаление)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "174d54a7-b104-4f3a-9672-5eaa8da5a212",
      "metadata": {
        "id": "174d54a7-b104-4f3a-9672-5eaa8da5a212"
      },
      "source": [
        "Удаление файлов с перемещением в корзину\n",
        "В HDFS:\n",
        "файлы по умолчанию удаляются в корзину, что позволяет восстановить их в случае необходимости.\n",
        "Корзина в HDFS функционирует аналогично корзине в операционных системах — файлы временно перемещаются в специальную директорию .Trash, откуда они могут быть восстановлены до окончательного удаления."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7eefad5-2140-4cd5-95a6-d8f37e6cc74d",
      "metadata": {
        "id": "a7eefad5-2140-4cd5-95a6-d8f37e6cc74d"
      },
      "source": [
        "Команда rm позволяет удалить файл/директорию:\n",
        "https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/FileSystemShell.html#rm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "212f1273-64e7-430c-901b-874588bbbecb",
      "metadata": {
        "id": "212f1273-64e7-430c-901b-874588bbbecb"
      },
      "source": [
        "Удаляем файл data1.csv, находящийся в директории testload1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7352bd35-5f23-42ec-8078-7212c199b6f9",
      "metadata": {
        "id": "7352bd35-5f23-42ec-8078-7212c199b6f9"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -rm /user/teacher_1/testload1/data1.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ef05a21-171e-4170-88f7-b7877a11f032",
      "metadata": {
        "id": "2ef05a21-171e-4170-88f7-b7877a11f032"
      },
      "source": [
        "Проверяем, что файл удалился:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31f5e37a-187e-4678-853a-9d669ac0b1a4",
      "metadata": {
        "id": "31f5e37a-187e-4678-853a-9d669ac0b1a4"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -ls testload1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1f17239-29cf-4742-911a-bbe6fe09b4bf",
      "metadata": {
        "id": "d1f17239-29cf-4742-911a-bbe6fe09b4bf"
      },
      "source": [
        "Проверяем появление скрытого каталога .Trash и наличие в нём ранее удалённого файла data1.csv:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8156b2ae-0310-4b70-8d97-195641f42760",
      "metadata": {
        "id": "8156b2ae-0310-4b70-8d97-195641f42760"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -lsr .Trash"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5605b3df-4636-4fea-bb8d-a9bde8249577",
      "metadata": {
        "id": "5605b3df-4636-4fea-bb8d-a9bde8249577"
      },
      "source": [
        "Удаляем директорию testload1, используя в команде аргумент -R:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba3edda8-4570-43ae-ad7d-4027f5ccb863",
      "metadata": {
        "id": "ba3edda8-4570-43ae-ad7d-4027f5ccb863"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -rm -R /user/teacher_1/testload1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a38648fa-dbda-4114-9708-96d0f24dddb6",
      "metadata": {
        "id": "a38648fa-dbda-4114-9708-96d0f24dddb6"
      },
      "source": [
        "Примечание: если необходимо, файл можно восстановить из корзины, используя команду mv (перемещение из директории .Trash)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b12ba4f-425d-4f65-85d3-7ffad1450222",
      "metadata": {
        "id": "1b12ba4f-425d-4f65-85d3-7ffad1450222"
      },
      "source": [
        "Удаление файлов без перемещения в корзину (окончательное удаление).\n",
        "\n",
        "Для необратимого удаления файлов и директорий в HDFS без перемещения в корзину используется опция -skipTrash.\n",
        "Это удобно, когда нужно немедленно освободить место или когда уверен, что данные больше не&nbsp;понадобятся."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2a7deba-03f5-4f7d-8cfb-fc017133a029",
      "metadata": {
        "id": "e2a7deba-03f5-4f7d-8cfb-fc017133a029"
      },
      "source": [
        "Удаляем файл data.csv без перемещения в корзину (окончательное удаление):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3477f276-b1ff-49e8-a804-cbec2cb37e64",
      "metadata": {
        "id": "3477f276-b1ff-49e8-a804-cbec2cb37e64"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -rm -skipTrash /user/teacher_1/testload/data.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be334c02-bfb4-4bb3-9e97-1ac9aa8631da",
      "metadata": {
        "id": "be334c02-bfb4-4bb3-9e97-1ac9aa8631da"
      },
      "source": [
        "Проверяем появление скрытого каталога .Trash и отсутствие в нём ранее удалённого файла data.csv:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5effc0e8-0f72-4dfc-b83e-4d150ec03ed5",
      "metadata": {
        "id": "5effc0e8-0f72-4dfc-b83e-4d150ec03ed5"
      },
      "outputs": [],
      "source": [
        "!hadoop fs -lsr .Trash"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09a2fe34-42e9-48b3-8314-ec5359624c05",
      "metadata": {
        "id": "09a2fe34-42e9-48b3-8314-ec5359624c05"
      },
      "source": [
        "## 6. Аналитика утилизации хранилища"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ada79b43-68c1-401f-b64a-75546e7788cc",
      "metadata": {
        "id": "ada79b43-68c1-401f-b64a-75546e7788cc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f228fc2-3bee-45c5-ba39-45e397405ea3",
      "metadata": {
        "id": "4f228fc2-3bee-45c5-ba39-45e397405ea3",
        "outputId": "027c9ffb-6d8a-4785-fb92-beccb2ae9fbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "b'-rw-r--r--   3 teacher_1 teacher_1    1475504 2024-09-06 11:02 /user/teacher_1/testload/data.csv\\ndrwxr-xr-x   - teacher_1 teacher_1          0 2024-09-06 15:07 /user/teacher_1/testload/output\\n-rw-r--r--   3 teacher_1 teacher_1          0 2024-09-06 15:07 /user/teacher_1/testload/output/_SUCCESS\\n-rw-r--r--   3 teacher_1 teacher_1        552 2024-09-06 15:07 /user/teacher_1/testload/output/part-r-00000\\n'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cmd = 'hdfs dfs -ls -R /user/teacher_1/testload'\n",
        "files = subprocess.check_output(cmd, shell=True)\n",
        "files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "201f7df0-92ed-4cf2-807c-c6e0e576f3e8",
      "metadata": {
        "id": "201f7df0-92ed-4cf2-807c-c6e0e576f3e8",
        "outputId": "893d13f3-84d1-4b25-8701-a2a2902109d9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>access</th>\n",
              "      <th>col1</th>\n",
              "      <th>user</th>\n",
              "      <th>group</th>\n",
              "      <th>size</th>\n",
              "      <th>date</th>\n",
              "      <th>time</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b'-rw-r--r--'</td>\n",
              "      <td>b'3'</td>\n",
              "      <td>b'teacher_1'</td>\n",
              "      <td>b'teacher_1'</td>\n",
              "      <td>b'1475504'</td>\n",
              "      <td>b'2024-09-06'</td>\n",
              "      <td>b'11:02'</td>\n",
              "      <td>b'/user/teacher_1/testload/data.csv'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b'drwxr-xr-x'</td>\n",
              "      <td>b'-'</td>\n",
              "      <td>b'teacher_1'</td>\n",
              "      <td>b'teacher_1'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'2024-09-06'</td>\n",
              "      <td>b'15:07'</td>\n",
              "      <td>b'/user/teacher_1/testload/output'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b'-rw-r--r--'</td>\n",
              "      <td>b'3'</td>\n",
              "      <td>b'teacher_1'</td>\n",
              "      <td>b'teacher_1'</td>\n",
              "      <td>b'0'</td>\n",
              "      <td>b'2024-09-06'</td>\n",
              "      <td>b'15:07'</td>\n",
              "      <td>b'/user/teacher_1/testload/output/_SUCCESS'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b'-rw-r--r--'</td>\n",
              "      <td>b'3'</td>\n",
              "      <td>b'teacher_1'</td>\n",
              "      <td>b'teacher_1'</td>\n",
              "      <td>b'552'</td>\n",
              "      <td>b'2024-09-06'</td>\n",
              "      <td>b'15:07'</td>\n",
              "      <td>b'/user/teacher_1/testload/output/part-r-00000'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          access  col1          user         group        size           date  \\\n",
              "0  b'-rw-r--r--'  b'3'  b'teacher_1'  b'teacher_1'  b'1475504'  b'2024-09-06'   \n",
              "1  b'drwxr-xr-x'  b'-'  b'teacher_1'  b'teacher_1'        b'0'  b'2024-09-06'   \n",
              "2  b'-rw-r--r--'  b'3'  b'teacher_1'  b'teacher_1'        b'0'  b'2024-09-06'   \n",
              "3  b'-rw-r--r--'  b'3'  b'teacher_1'  b'teacher_1'      b'552'  b'2024-09-06'   \n",
              "\n",
              "       time                                             path  \n",
              "0  b'11:02'             b'/user/teacher_1/testload/data.csv'  \n",
              "1  b'15:07'               b'/user/teacher_1/testload/output'  \n",
              "2  b'15:07'      b'/user/teacher_1/testload/output/_SUCCESS'  \n",
              "3  b'15:07'  b'/user/teacher_1/testload/output/part-r-00000'  "
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_rows = files.split()\n",
        "rows = [[all_rows[j+i] for j in range(8)] for i in range(0,len(all_rows),8)]\n",
        "tc = pd.DataFrame(rows, columns= ['access','col1','user','group','size','date','time','path'])\n",
        "tc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f505d40-5a17-447f-a421-11f8bd2ecb11",
      "metadata": {
        "scrolled": true,
        "id": "6f505d40-5a17-447f-a421-11f8bd2ecb11",
        "outputId": "bd00dd3b-166d-4de2-c9f3-110aed359e0d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>access</th>\n",
              "      <th>col1</th>\n",
              "      <th>user</th>\n",
              "      <th>group</th>\n",
              "      <th>size</th>\n",
              "      <th>date</th>\n",
              "      <th>time</th>\n",
              "      <th>path</th>\n",
              "      <th>updated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-rw-r--r--</td>\n",
              "      <td>3</td>\n",
              "      <td>teacher_1</td>\n",
              "      <td>teacher_1</td>\n",
              "      <td>1475504</td>\n",
              "      <td>2024-09-06</td>\n",
              "      <td>11:02</td>\n",
              "      <td>/user/teacher_1/testload/data.csv</td>\n",
              "      <td>2024-09-06 11:02:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>drwxr-xr-x</td>\n",
              "      <td>-</td>\n",
              "      <td>teacher_1</td>\n",
              "      <td>teacher_1</td>\n",
              "      <td>0</td>\n",
              "      <td>2024-09-06</td>\n",
              "      <td>15:07</td>\n",
              "      <td>/user/teacher_1/testload/output</td>\n",
              "      <td>2024-09-06 15:07:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-rw-r--r--</td>\n",
              "      <td>3</td>\n",
              "      <td>teacher_1</td>\n",
              "      <td>teacher_1</td>\n",
              "      <td>0</td>\n",
              "      <td>2024-09-06</td>\n",
              "      <td>15:07</td>\n",
              "      <td>/user/teacher_1/testload/output/_SUCCESS</td>\n",
              "      <td>2024-09-06 15:07:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-rw-r--r--</td>\n",
              "      <td>3</td>\n",
              "      <td>teacher_1</td>\n",
              "      <td>teacher_1</td>\n",
              "      <td>552</td>\n",
              "      <td>2024-09-06</td>\n",
              "      <td>15:07</td>\n",
              "      <td>/user/teacher_1/testload/output/part-r-00000</td>\n",
              "      <td>2024-09-06 15:07:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       access col1       user      group     size        date   time  \\\n",
              "0  -rw-r--r--    3  teacher_1  teacher_1  1475504  2024-09-06  11:02   \n",
              "1  drwxr-xr-x    -  teacher_1  teacher_1        0  2024-09-06  15:07   \n",
              "2  -rw-r--r--    3  teacher_1  teacher_1        0  2024-09-06  15:07   \n",
              "3  -rw-r--r--    3  teacher_1  teacher_1      552  2024-09-06  15:07   \n",
              "\n",
              "                                           path             updated  \n",
              "0             /user/teacher_1/testload/data.csv 2024-09-06 11:02:00  \n",
              "1               /user/teacher_1/testload/output 2024-09-06 15:07:00  \n",
              "2      /user/teacher_1/testload/output/_SUCCESS 2024-09-06 15:07:00  \n",
              "3  /user/teacher_1/testload/output/part-r-00000 2024-09-06 15:07:00  "
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for column in tc.columns:\n",
        "    tc[column]=tc[column].apply(lambda x:x.decode(\"utf-8\"))\n",
        "tc['updated'] = pd.to_datetime(tc['date'] +' '+ tc['time'])\n",
        "tc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb3c25ee-20e6-41d5-a1bf-aa11901c2df0",
      "metadata": {
        "id": "eb3c25ee-20e6-41d5-a1bf-aa11901c2df0",
        "outputId": "d728495d-e465-4421-a485-cf6a17b7a335"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Утилизация хранилища: 1.41 MB\n",
            "Дата последнего обновления: 2024-09-06 15:07:00\n"
          ]
        }
      ],
      "source": [
        "print(f\"Утилизация хранилища: {round(tc['size'].astype(int).sum()/1024/1024,2)} MB\")\n",
        "print(f\"Дата последнего обновления: {tc['updated'].max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aff3640a-b87d-4b6b-87e2-27e44fecbcfb",
      "metadata": {
        "id": "aff3640a-b87d-4b6b-87e2-27e44fecbcfb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c279bff-96b3-4a34-b35d-c5ea89e4ea59",
      "metadata": {
        "id": "2c279bff-96b3-4a34-b35d-c5ea89e4ea59"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}